## 深度学习（神经网路）

***TODO: 目前分类杂乱，先将知识点罗列整理，后续再加以分类***

#### 神经网络并不是一个新的概念，不过，得益于近些年大数据的发展，机器性能的提升，神经网络的能力得到展现，开始成为人工智能领域的主力军。

#### 提纲
+ loss
  + 交叉熵
  + MSE
+ metrics 评价指标
+ optimizer
+ 梯度下降
+ 全连接网络
+ 残差网络
+ 卷积网络
+ batch-normalize / BN
+ 1 x 1 卷积
+ 注意力机制
+ 监督
+ 自监督
+ 迁移学习
+ 强化学习
+ 生成对抗网络
+ 循环网络
+ 分类
+ 回归
+ 图像识别
+ 图像检测
+ 图像分割
+ C3D 
+ one-hot编码
+ 词袋模型
+ 论文 
+ 征引


## 正文

### 评价指标

#### 分类器的评价指标

***

##### 混淆矩阵 confusion matrix

以二分类为例：
![二分类混淆矩阵](imgs/confusion_matrix.jpg)

***

##### Accuracy, Recall, Precison, Specificity, F1
##### 准确率，召回率，精度，特异度，F1, F$\bm{_\beta}$

$Accuray = \frac{(TP + TN)}{(TP + TN + FN + TN)}$

$Recall = \frac{TP}{TP + FN}$

$Precision = \frac{TP}{TP + FP}$

$Specificity = \frac{TN}{TN + FN}$ 

$F1 = \frac{2 \times (Precision \times Recall)}{Precision + Recall}$

关于F1：

    F1是Precision和Recall的调和平均数(倒数算术平均数的倒数),
    调和平均数的特点是强调小元素，忽略大元素。
    如果一个分类器的F1很高，则该分类器的Precision和Recall一定同时很高。
    如果Recall很大，Precision很小，那么F1的值也是很小的
    极端来说，如果Recall=1，Precision=0，此时F1=0

$F_\bm{\beta} = \frac{((1 + (\beta)^{2}) \times (Precision \times Recall)}{((\beta)^{2} \times Precision) + Recall}$

$F_\bm{\beta}$的使用场景出现在，当你对Precision和Recall中某一个指标更感兴趣时。如果你更看重Precision，那么$\bm{\beta}$的值应该小于1，如果你更看重Recall，那么$\bm{\beta}$的值应该大于1.

***

##### ROC
Receiver Operating Characteristic Curve
最初是为军事雷达接收器的操作者设计的，所以如此命名。

横坐标为 伪阳性率(FPR, False Positive Rate)
$FPR = \frac{FP}{N} = \frac{FP}{FP + TN}$

纵坐标为 真阳性率(TPR，Ture Positive Rate)(Recall)
$TPR = \frac{TP}{P} = \frac{TP}{TP + FN}$

ROC曲线用于绘制采用不同分类阈值时的TPR与FPR。降低分类阈值，会有更多样本被划分为Positive.假正例与真正例都会增加。所以曲线从左向右呈现攀升趋势。
理想情况下，ROC曲线为一点 (0, 1)
![ROC示意图](imgs/ROCCurve.svg "图片来自谷歌")
<!-- [ROC示意图](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) -->

##### AUC
Area Under the Curve
![AUC](imgs/AUC.svg "图片来自谷歌")

曲线下面积对所有可能的分类阈值的效果进行综合衡量。曲线下面积的一种解读方式是看作模型将某个随机正类别样本排列在某个随机负类别样本之上的概率。

>理论公式如下:
>$$TPR(T): T \rightarrow y(x)$$
>$$FPR(T): T \rightarrow x$$
>![wikiAuc](imgs/wikiAuc.svg)
>$T$为选取的阈值，$X_1$为一个随机正例的预测得分，$X_0$为一个随机负例的预测得分。$f_1, f_0$分别是正例和负例的概率密度。


以下面的样本为例，逻辑回归预测从左到右以升序排列：
![AUCPredictionsRanked](imgs/AUCPredictionsRanked.svg "图片来自谷歌")

曲线下面积表示随机正类别（绿色）样本位于随机负类别（红色）样本右侧的概率。
曲线下面积的取值范围为 0-1。预测结果 100% 错误的模型的曲线下面积为 0.0；而预测结果 100% 正确的模型的曲线下面积为 1.0。









***
####Reference
+ [谷歌机器学习教程](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)
+ [sklearn reference](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)
+ [wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)